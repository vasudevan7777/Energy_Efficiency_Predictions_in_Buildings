{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# streamlit_app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import joblib\n",
        "import os\n",
        "from io import BytesIO\n",
        "\n",
        "st.set_page_config(page_title=\"Energy Efficiency - Buildings\", layout=\"wide\")\n",
        "st.title(\"üè† Energy Efficiency Prediction (Heating & Cooling Load)\")\n",
        "\n",
        "# ---------- helper functions ----------\n",
        "@st.cache_data\n",
        "def load_uci_dataset():\n",
        "    \"\"\"Load UCI ENB2012 dataset from url (xlsx). If URL blocked, the app will show instructions.\"\"\"\n",
        "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx\"\n",
        "    try:\n",
        "        df = pd.read_excel(url)\n",
        "    except Exception as e:\n",
        "        st.error(\"Could not download UCI dataset automatically. Please use the file uploader (Excel/CSV) or place the dataset in data/ folder.\")\n",
        "        raise e\n",
        "    # Rename columns (UCI sheet has no friendly headers)\n",
        "    df.columns = [\"Relative_Compactness\",\"Surface_Area\",\"Wall_Area\",\"Roof_Area\",\n",
        "                  \"Overall_Height\",\"Orientation\",\"Glazing_Area\",\"Glazing_Area_Distribution\",\n",
        "                  \"Heating_Load\",\"Cooling_Load\"]\n",
        "    return df\n",
        "\n",
        "def read_user_file(uploaded_file):\n",
        "    if uploaded_file is None:\n",
        "        return None\n",
        "    fname = uploaded_file.name.lower()\n",
        "    if fname.endswith(\".xlsx\") or fname.endswith(\".xls\"):\n",
        "        return pd.read_excel(uploaded_file)\n",
        "    elif fname.endswith(\".csv\"):\n",
        "        return pd.read_csv(uploaded_file)\n",
        "    else:\n",
        "        st.error(\"Unsupported file type. Upload CSV or Excel.\")\n",
        "        return None\n",
        "\n",
        "def preprocess_df(df):\n",
        "    # Try to ensure required columns exist; rename if possible\n",
        "    expected = {\"Relative_Compactness\",\"Surface_Area\",\"Wall_Area\",\"Roof_Area\",\n",
        "                \"Overall_Height\",\"Orientation\",\"Glazing_Area\",\"Glazing_Area_Distribution\",\n",
        "                \"Heating_Load\",\"Cooling_Load\"}\n",
        "    # Basic cleaning\n",
        "    df = df.copy()\n",
        "    df = df.dropna(how=\"all\")  # drop empty rows\n",
        "    # If dataset has similar headers but different names, user must ensure correct columns.\n",
        "    found = set(df.columns)\n",
        "    if not expected.issubset(found):\n",
        "        # If Heating/Cooling columns missing, attempt lowercase match\n",
        "        lower_map = {c.lower(): c for c in df.columns}\n",
        "        mapping = {}\n",
        "        for e in expected:\n",
        "            if e.lower() in lower_map:\n",
        "                mapping[lower_map[e.lower()]] = e\n",
        "        if mapping:\n",
        "            df = df.rename(columns=mapping)\n",
        "    return df\n",
        "\n",
        "# ---------- Sidebar: dataset options ----------\n",
        "st.sidebar.header(\"Dataset options\")\n",
        "uploaded_file = st.sidebar.file_uploader(\"Upload your dataset (Excel or CSV). If you don't upload one, the UCI dataset will be used.\", type=[\"xlsx\",\"xls\",\"csv\"])\n",
        "merge_with_uci = st.sidebar.checkbox(\"If I upload a dataset, merge it with UCI dataset (append rows)\", value=False)\n",
        "use_local_file = st.sidebar.checkbox(\"Load dataset from local file path (data/user_dataset.xlsx)\", value=False)\n",
        "local_path = \"data/user_dataset.xlsx\"\n",
        "\n",
        "# ---------- Load data logic ----------\n",
        "df_user = read_user_file(uploaded_file) if uploaded_file else None\n",
        "df_uci = None\n",
        "df = None\n",
        "\n",
        "# Try to load UCI dataset (if needed)\n",
        "if (uploaded_file is None) or (uploaded_file is not None and merge_with_uci) or use_local_file:\n",
        "    try:\n",
        "        df_uci = load_uci_dataset()\n",
        "    except Exception:\n",
        "        df_uci = None\n",
        "\n",
        "if use_local_file and os.path.exists(local_path):\n",
        "    try:\n",
        "        df_local = pd.read_excel(local_path) if local_path.endswith((\"xlsx\",\"xls\")) else pd.read_csv(local_path)\n",
        "        df_local = preprocess_df(df_local)\n",
        "        if df_uci is None:\n",
        "            df = df_local\n",
        "        else:\n",
        "            df = pd.concat([df_uci, df_local], ignore_index=True)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to read local file at {local_path}: {e}\")\n",
        "else:\n",
        "    if df_user is not None:\n",
        "        df_user = preprocess_df(df_user)\n",
        "        if merge_with_uci and df_uci is not None:\n",
        "            df = pd.concat([df_uci, df_user], ignore_index=True)\n",
        "        else:\n",
        "            df = df_user\n",
        "    else:\n",
        "        df = df_uci\n",
        "\n",
        "if df is None:\n",
        "    st.stop()\n",
        "\n",
        "# show dataset\n",
        "st.subheader(\"üìä Dataset preview (first 10 rows)\")\n",
        "st.dataframe(df.head(10))\n",
        "\n",
        "# ---------- Check for required target columns ----------\n",
        "required_cols = [\"Heating_Load\", \"Cooling_Load\"]\n",
        "if not all(c in df.columns for c in required_cols):\n",
        "    st.error(\"Dataset does not contain both 'Heating_Load' and 'Cooling_Load' columns. Please upload/prepare the dataset in the same format as the UCI ENB2012 dataset.\")\n",
        "    st.stop()\n",
        "\n",
        "# ---------- Features & preprocessing ----------\n",
        "feature_cols = [\"Relative_Compactness\",\"Surface_Area\",\"Wall_Area\",\"Roof_Area\",\n",
        "                \"Overall_Height\",\"Orientation\",\"Glazing_Area\",\"Glazing_Area_Distribution\"]\n",
        "for c in feature_cols:\n",
        "    if c not in df.columns:\n",
        "        st.error(f\"Missing feature column: {c}. Ensure your dataset uses the same column names as the UCI dataset.\")\n",
        "        st.stop()\n",
        "\n",
        "X = df[feature_cols].astype(float)\n",
        "y = df[required_cols].astype(float)\n",
        "\n",
        "# split\n",
        "test_size = st.sidebar.slider(\"Test set proportion (%)\", 5, 50, 20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size/100.0, random_state=42)\n",
        "\n",
        "# ---------- Train model ----------\n",
        "st.subheader(\"‚öôÔ∏è Train model\")\n",
        "n_estimators = st.sidebar.slider(\"n_estimators (RandomForest)\", 50, 500, 200, step=10)\n",
        "train_button = st.button(\"Train RandomForest model now\")\n",
        "\n",
        "model_path = \"models/energy_model.pkl\"\n",
        "if train_button:\n",
        "    model = RandomForestRegressor(n_estimators=n_estimators, random_state=42, n_jobs=-1)\n",
        "    with st.spinner(\"Training model...\"):\n",
        "        model.fit(X_train, y_train)\n",
        "        os.makedirs(\"models\", exist_ok=True)\n",
        "        joblib.dump(model, model_path)\n",
        "    st.success(f\"Model trained and saved to {model_path}\")\n",
        "\n",
        "# If model exists, load it (so UI can be used without retraining)\n",
        "if os.path.exists(model_path):\n",
        "    model = joblib.load(model_path)\n",
        "else:\n",
        "    # if user didn't train, train automatically (small convenience)\n",
        "    model = RandomForestRegressor(n_estimators=n_estimators, random_state=42, n_jobs=-1)\n",
        "    model.fit(X_train, y_train)\n",
        "    os.makedirs(\"models\", exist_ok=True)\n",
        "    joblib.dump(model, model_path)\n",
        "\n",
        "# ---------- Evaluate ----------\n",
        "st.subheader(\"üìà Evaluation on test set\")\n",
        "y_pred = model.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "st.write(f\"R¬≤ score: **{r2:.4f}**\")\n",
        "st.write(f\"RMSE (multi-output averaged): **{rmse:.4f}**\")\n",
        "\n",
        "# show sample predictions\n",
        "sample_df = X_test.copy().reset_index(drop=True).head(5)\n",
        "sample_preds = model.predict(sample_df)\n",
        "st.write(\"Sample test inputs and model predictions (first 5):\")\n",
        "res = sample_df.copy()\n",
        "res[\"Pred_Heating\"] = sample_preds[:,0]\n",
        "res[\"Pred_Cooling\"] = sample_preds[:,1]\n",
        "st.dataframe(res)\n",
        "\n",
        "# ---------- Predict from user input ----------\n",
        "st.subheader(\"üîÆ Make a custom prediction\")\n",
        "# give sliders based on dataset ranges\n",
        "def minmax(col):\n",
        "    return float(X[col].min()), float(X[col].max()), float(X[col].median())\n",
        "\n",
        "input_data = {}\n",
        "cols = {}\n",
        "for col in feature_cols:\n",
        "    mn, mx, med = minmax(col)\n",
        "    if col in [\"Orientation\",\"Glazing_Area_Distribution\"]:\n",
        "        # discrete choices\n",
        "        choices = sorted(list(X[col].unique()))\n",
        "        input_data[col] = st.selectbox(col, choices, index=choices.index(int(med)) if int(med) in choices else 0)\n",
        "    else:\n",
        "        input_data[col] = st.slider(col, min_value=mn, max_value=mx, value=med)\n",
        "\n",
        "input_df = pd.DataFrame([input_data])[feature_cols]\n",
        "\n",
        "if st.button(\"Predict for above input\"):\n",
        "    pred = model.predict(input_df)[0]\n",
        "    st.success(f\"Predicted Heating Load: **{pred[0]:.2f}**\")\n",
        "    st.success(f\"Predicted Cooling Load: **{pred[1]:.2f}**\")\n",
        "\n",
        "# ---------- Download model ----------\n",
        "st.subheader(\"‚¨áÔ∏è Download trained model\")\n",
        "with open(model_path, \"rb\") as f:\n",
        "    bytes_model = f.read()\n",
        "st.download_button(label=\"Download model (.pkl)\", data=bytes_model, file_name=\"energy_model.pkl\")\n",
        "\n",
        "st.write(\"App finished. Tip: If you uploaded a custom dataset, make sure its columns match the UCI dataset column names.\")\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
